apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: ecommerce-streaming
  namespace: default
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  sparkVersion: "3.5.0"

  sparkConf:
    # 1. Tải dependencies
    spark.jars.packages: "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,com.clickhouse:clickhouse-jdbc:0.5.0"

    # 2. Đặt cache Ivy vào /tmp (khắc phục lỗi FileNotFoundException)
    spark.jars.ivy: "/tmp/.ivy2"

    # 3. BUỘC Spark phân phối JARs vào thư mục /tmp (khắc phục lỗi Read-only File System)
    spark.kubernetes.resourceStagingDirectory: "/tmp/spark-staging"

  driver:
    image: "docker.io/library/spark-kafka:v2.0"
    cores: 1
    coreLimit: "1200m"
    memory: "1g"
    serviceAccount: spark-operator-spark
    volumeMounts:
      # Giữ nguyên mount ConfigMap để có code Python
      - name: spark-job
        mountPath: /opt/spark/work-dir

  executor:
    image: "docker.io/library/spark-kafka:v2.0"
    cores: 1
    instances: 2
    memory: "1g"
    volumeMounts:
      - name: spark-job
        mountPath: /opt/spark/work-dir

  mainApplicationFile: local:///opt/spark/work-dir/ecommerce_stream.py

  volumes:
    - name: spark-job
      configMap:
        name: spark-ecommerce-job